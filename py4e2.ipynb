{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.4 Write a program to read through the mbox-short.txt and figure out who has sent the greatest number of mail messages. The program looks for 'From ' lines and takes the second word of those lines as the person who sent the mail. The program creates a Python dictionary that maps the sender's mail address to a count of the number of times they appear in the file. After the dictionary is produced, the program reads through the dictionary using a maximum loop to find the most prolific committer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = input(\"Enter file:\")\n",
    "if len(name) < 1 : name = \"mbox-short.txt\"\n",
    "handle = open(name)\n",
    "babe = dict()\n",
    "for item, value in babe.items():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'From anitaigbine@gmail.com Sat Jan 5 09:14:16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using String Find Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To extract the section after the '@' sign\n",
    "atpos = data.find('@')\n",
    "sppos = data.find(' ', atpos)\n",
    "back = data[atpos+1:sppos]\n",
    "print(back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Split Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onesplit = data.split()\n",
    "ext = onesplit[1]\n",
    "usl = ext.split('@')\n",
    "domain = usl[1]\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = re.findall('@([^ ]*)', data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = re.findall('^From .*@([^ ]*)',data)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = open('mbox-short.txt')\n",
    "numlist = list()\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    stuff = re.findall('^X-DSPAM-Confidence: ([0-9.]+)', line)\n",
    "    if len(stuff) != 1: continue\n",
    "    num = float(stuff[0])\n",
    "    numlist.append(num)\n",
    "print('Maximum:', max(numlist))\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zimmer = 'Wwe just received $10.00 for cookies.'\n",
    "#To indicate that you really want a sign/character, use the '\\'\n",
    "zim = re.findall('\\$[0-9.]+', zimmer)\n",
    "print(zim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    if re.search('From:', line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    xy = line.find('From:')\n",
    "    print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'A message from csev@umich.edu to cwen@iupui.edu about meeting @2PM'\n",
    "lst = re.findall('\\S+@\\S+', s)\n",
    "print(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that have an at sign between characters\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('\\S+@\\S+', line)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that have an at sign between characters\n",
    "import re\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('\\S+@\\S+', line)\n",
    "    if len(x) > 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that have an at sign between characters\n",
    "# The characters must be a letter or number\n",
    "import re\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('[a-zA-Z0-9]\\S+@\\S+[a-zA-Z]', line)\n",
    "    if len(x) > 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that start with 'X' followed by any non\n",
    "# whitespace characters and ':'\n",
    "# followed by a space and any number.\n",
    "# The number can include a decimal.\n",
    "import re\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    if re.search('^X\\S*: [0-9.]+', line):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parentheses are another special character in regular expressions. When you add\n",
    "parentheses to a regular expression, they are ignored when matching the string.\n",
    "But when you are using findall(), parentheses indicate that while you want the\n",
    "whole expression to match, you only are interested in extracting a portion of the\n",
    "substring that matches the regular expression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that start with 'X' followed by any\n",
    "# non whitespace characters and ':' followed by a space\n",
    "# and any number. The number can include a decimal.\n",
    "# Then print the number if it is greater than zero.\n",
    "import re\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('^X\\S*: ([0-9.]+)', line)\n",
    "    if len(x) > 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we wanted to extract all of the revision numbers (the integer number at the end\n",
    "of these lines) using the same technique as above, we could write the following\n",
    "program:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that start with 'Details: rev='\n",
    "# followed by numbers and '.'\n",
    "# Then print the number if it is greater than zero\n",
    "import re\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('^Details:.*rev=([0-9.]+)', line)\n",
    "    if len(x) > 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for lines that start with From and a character\n",
    "# followed by a two digit number between 00 and 99 followed by ':'\n",
    "# Then print the number if it is greater than zero\n",
    "import re\n",
    "hand = open('mbox-short.txt')\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('^From .* ([0-9][0-9]):', line)\n",
    "    if len(x) > 0: print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we prefix the dollar sign with a backslash, it actually matches the dollar\n",
    "sign in the input string instead of matching the “end of line”, and the rest of\n",
    "the regular expression matches one or more digits or the period character. Note:\n",
    "Inside square brackets, characters are not “special”. So when we say [0-9.], it\n",
    "really means digits or a period. Outside of square brackets, a period is the “wildcard” character and matches any character. Inside square brackets, the period is\n",
    "a period.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'From: Using the : character'\n",
    "y = re.findall('^F.+:', x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'\n",
    "y = re.findall('\\S+?@\\S+',x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = open('regex_sum_927502.txt')\n",
    "numlist=[]\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('[0-9]+', line)\n",
    "    for item in x:\n",
    "        if len(x) > 0:\n",
    "     \n",
    "            item = int(item)\n",
    "            numlist.append(item)\n",
    "\n",
    "summ = 0\n",
    "for item in numlist:\n",
    "    summ = item + summ\n",
    "print(summ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HyperText Transfer Protocol is a set of rules that allows browsers retrieve web documents from the internet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\n\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(), end=' ')\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import time\n",
    "\n",
    "HOST = 'data.pr4e.org'\n",
    "PORT = 80\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect((HOST, PORT))\n",
    "mysock.sendall(b'GET http://data.pr4e.org/cover3.jpg HTTP/1.0\\r\\n\\r\\n')\n",
    "count = 0\n",
    "picture = b\"\"\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(5120)\n",
    "    if len(data) < 1: break\n",
    "    #time.sleep(0.25)\n",
    "    count = count + len(data)\n",
    "    print(len(data), count)\n",
    "    picture = picture + data\n",
    "\n",
    "mysock.close()\n",
    "\n",
    "# Look for the end of the header (2 CRLF)\n",
    "pos = picture.find(b\"\\r\\n\\r\\n\")\n",
    "print('Header length', pos)\n",
    "print(picture[:pos].decode())\n",
    "\n",
    "# Skip past the header and save the picture data\n",
    "picture = picture[pos+4:]\n",
    "fhand = open(\"stuff.jpg\", \"wb\")\n",
    "fhand.write(picture)\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While we can manually send and receive data over HTTP using the socket library,\n",
    "there is a much simpler way to perform this common task in Python by using the\n",
    "urllib library.\n",
    "Using urllib, you can treat a web page much like a file. You simply indicate\n",
    "which web page you would like to retrieve and urllib handles all of the HTTP\n",
    "protocol and header details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When the program runs, we only see the output of the contents of the file. The\n",
    "headers are still sent, but the urllib code consumes the headers and only returns\n",
    "the data to us.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As an example, we can write a program to retrieve the data for romeo.txt and\n",
    "#compute the frequency of each word in the file as follows:\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sometimes you want to retrieve a non-text (or binary) file such as an image or\n",
    "video file. The data in these files is generally not useful to print out, but you can\n",
    "easily make a copy of a URL to a local file on your hard disk using urllib.\n",
    "The pattern is to open the URL and use read to download the entire contents of\n",
    "the document into a string variable (img) then write that information to a local\n",
    "file as follows:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg').read()\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "fhand.write(img)\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However if this is a large audio or video file, this program may crash or at least\n",
    "run extremely slowly when your computer runs out of memory. In order to avoid running out of memory, we retrieve the data in blocks (or buffers) and then write\n",
    "each block to your disk before retrieving the next block. This way the program can\n",
    "read any size file without using up all of the memory you have in your computer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "img = urllib.request.urlopen('http://data.pr4e.org/cover3.jpg')\n",
    "fhand = open('cover3.jpg', 'wb')\n",
    "size = 0\n",
    "while True:\n",
    "    info = img.read(100000)\n",
    "    if len(info) < 1: break\n",
    "    size = size + len(info)\n",
    "    fhand.write(info)\n",
    "\n",
    "print(size, 'characters copied.')\n",
    "fhand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HTML and scraping the web\n",
    "One of the common uses of the urllib capability in Python is to scrape the web.\n",
    "Web scraping is when we write a program that pretends to be a web browser and\n",
    "retrieves pages, then examines the data in those pages looking for patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for link values within URL input\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import re\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "links = re.findall(b'href=\"(http[s]?://.*?)\"', html)\n",
    "for link in links:\n",
    "    print(link.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions work very nicely when your HTML is well formatted and\n",
    "predictable. But since there are a lot of “broken” HTML pages out there, a solution\n",
    "only using regular expressions might either miss some valid links or end up with\n",
    "bad data.\n",
    "This can be solved by using a robust HTML parsing library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though HTML looks like XML1 and some pages are carefully constructed to\n",
    "be XML, most HTML is generally broken in ways that cause an XML parser to\n",
    "reject the entire page of HTML as improperly formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program prompts for a web address, then opens the web page, reads the data\n",
    "and passes the data to the BeautifulSoup parser, and then retrieves all of the\n",
    "anchor tags and prints out the href attribute for each tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand = open('regex_sum_927502.txt')\n",
    "numlist=[]\n",
    "for line in hand:\n",
    "    line = line.rstrip()\n",
    "    x = re.findall('[0-9]+', line)\n",
    "    for item in x:\n",
    "        if len(x) > 0:\n",
    "     \n",
    "            item = int(item)\n",
    "            numlist.append(item)\n",
    "\n",
    "summ = 0\n",
    "for item in numlist:\n",
    "    summ = item + summ\n",
    "print(summ)\n",
    "\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "itemlist = []\n",
    "tags = soup('span')\n",
    "for tag in tags:\n",
    "    # Look at the parts of a tag\n",
    "    itemlist.append(list(tag))\n",
    "\n",
    "\n",
    "numlist = []\n",
    "for item in itemlist:\n",
    "    numlist.append(item[0])\n",
    "    \n",
    "total = 0\n",
    "for num in numlist:\n",
    "    num = int(num)\n",
    "    total = total + num\n",
    "\n",
    "    \n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET import socket'\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "#mysock.close()\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "#######################################\n",
    "#mport urllib\n",
    "#rom bs4 import BeautifulSoup\n",
    "\n",
    "#rl = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "#tml = urllib.request.urlopen(url).read()\n",
    "#oup = BeautifulSoup(html, 'html.parser')\n",
    "#ount = 5\n",
    "#osition = 3\n",
    "#ags_lst = []\n",
    "\n",
    "#or x in range(count-1):\n",
    "#   tags = soup('a')\n",
    "#  my_tags = tags[position-1]\n",
    "#   needed_tag = my_tags.get('href', None)\n",
    "#   tags_lst.append(needed_tag)\n",
    "#   url = str(needed_tag)\n",
    "#   html = urllib.request.urlopen(url).read()\n",
    "#   soup = BeautifulSoup(html, 'html.parser')\n",
    "#rint(tags_lst)\n",
    "#########################################\n",
    "def parselink(position, limit):\n",
    "    url = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "    html = urllib.request.urlopen(url, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    taglist =[]\n",
    "    namelist =[]\n",
    "    tags = soup('a')\n",
    "    for tag in tags:\n",
    "        for anchor in soup.findAll('a'):\n",
    "            namelist.append(anchor.string)\n",
    "    print(namelist)\n",
    "            \n",
    "            \n",
    "parselink(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "count = 5\n",
    "position = 3\n",
    "tags_lst = []\n",
    "\n",
    "for x in range(count-1):\n",
    "    tags = soup('a')\n",
    "    my_tags = tags[position-1]\n",
    "    needed_tag = my_tags.get('href', None)\n",
    "    tags_lst.append(needed_tag)\n",
    "    url = str(needed_tag)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "print(tags_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "\n",
    "def parselink(num, limit):\n",
    "    url = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "    while num <limit:\n",
    "        #rl = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html'\n",
    "        html = urllib.request.urlopen(url, context=ctx).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        taglist = []\n",
    "        namelist = []\n",
    "        tags = soup('a')\n",
    "        for tag in tags:\n",
    "            taglist.append(tag.get('href', None))\n",
    "        url == taglist[2]\n",
    "        print(taglist[2])\n",
    "        new_url = taglist[2]\n",
    "        print(new_url)\n",
    "        #html = urllib.request.urlopen(new_url, context=ctx).read()\n",
    "        num += 1\n",
    "\n",
    "    \n",
    "parselink(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "\n",
    "def parselink(position, limit):\n",
    "    \n",
    "    \n",
    "    '''Position is the same as given in the question\n",
    "  the program minuses 1 from this because the assignment index\n",
    "  starts from i not 0\n",
    "  Limit is the number of times the process is repeated.\n",
    "  Same as in the assignment position.'''\n",
    "    \n",
    "    taglist = []\n",
    "    url = 'http://py4e-data.dr-chuck.net/known_by_Abhia.html'\n",
    "    html = urllib.request.urlopen(url, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "  \n",
    "    #tags = soup('a') \n",
    "    for i in range(limit):\n",
    "        tags = soup('a')\n",
    "        my_tag = tags[position-1]\n",
    "        needed_tag = my_tag.get('href', None)\n",
    "        taglist.append(needed_tag)\n",
    "        url = needed_tag\n",
    "        html = urllib.request.urlopen(url, context=ctx).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    for tag in taglist:\n",
    "        undrscr= tag.find('y_')\n",
    "        fullstp = tag.find('.', undrscr)\n",
    "        name = tag[undrscr+2:fullstp]\n",
    "        print(name)\n",
    "\n",
    "    \n",
    "parselink(18,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/xml?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/xml?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "\n",
    "    data = uh.read()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    print(data.decode())\n",
    "    tree = ET.fromstring(data)\n",
    "\n",
    "    results = tree.findall('commentinfo')\n",
    "    for item in results:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.fromstring(data)\n",
    "\n",
    "    results = tree.findall('result')\n",
    "    lat = results[0].find('geometry').find('location').find('lat').text\n",
    "    lng = results[0].find('geometry').find('location').find('lng').text\n",
    "    location = results[0].find('formatted_address').text\n",
    "\n",
    "    print('lat', lat, 'lng', lng)\n",
    "    print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location: http://py4e-data.dr-chuck.net/comments_927506.xml\n",
      "Retrieved 4212 characters\n",
      "count: 2458\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/xml?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/xml?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    uh = urllib.request.urlopen(address, context=ctx)\n",
    "\n",
    "    data = uh.read()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "    #print(data.decode())\n",
    "    tree = ET.fromstring(data)\n",
    "\n",
    "    results = tree.findall('comments/comment')\n",
    "    \n",
    "    for item in results:\n",
    "        item = int(item.find('count').text)\n",
    "        count+= item\n",
    "    \n",
    "    print('count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "sum=0\n",
    "\n",
    "address = input('Enter location: ')\n",
    "uh = urllib.request.urlopen(address)\n",
    "data = uh.read()\n",
    "tree = ET.fromstring(data)\n",
    "\n",
    "\n",
    "\n",
    "for count in tree.findall('comments/comment'):\n",
    "    rank = int(count.find('count').text)\n",
    "    sum=sum+rank\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JavaSript Object Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-13c0ae49e289>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-13c0ae49e289>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    data =\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = '''\n",
    "[\n",
    "  { \"id\" : \"001\",\n",
    "    \"x\" : \"2\",\n",
    "    \"name\" : \"Chuck\"\n",
    "  } ,\n",
    "  { \"id\" : \"009\",\n",
    "    \"x\" : \"7\",\n",
    "    \"name\" : \"Brent\"\n",
    "  }\n",
    "]'''\n",
    "\n",
    "info = json.loads(data)\n",
    "print('User count:', len(info))\n",
    "\n",
    "for item in info:\n",
    "    print('Name', item['name'])\n",
    "    print('Id', item['id'])\n",
    "    print('Attribute', item['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "data = '''\n",
    "[\n",
    "    {\n",
    "      \"name\":\"Romina\",\n",
    "      \"count\":97\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Laurie\",\n",
    "      \"count\":97\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Bayli\",\n",
    "      \"count\":90\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Siyona\",\n",
    "      \"count\":90\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Taisha\",\n",
    "      \"count\":88\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Alanda\",\n",
    "      \"count\":87\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Ameelia\",\n",
    "      \"count\":87\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Prasheeta\",\n",
    "      \"count\":80\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Asif\",\n",
    "      \"count\":79\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Risa\",\n",
    "      \"count\":79\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Zi\",\n",
    "      \"count\":78\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Danyil\",\n",
    "      \"count\":76\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Ediomi\",\n",
    "      \"count\":76\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Barry\",\n",
    "      \"count\":72\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Lance\",\n",
    "      \"count\":72\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Hattie\",\n",
    "      \"count\":66\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Mathu\",\n",
    "      \"count\":66\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Bowie\",\n",
    "      \"count\":65\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Samara\",\n",
    "      \"count\":65\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Uchenna\",\n",
    "      \"count\":64\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Shauni\",\n",
    "      \"count\":61\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Georgia\",\n",
    "      \"count\":61\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Rivan\",\n",
    "      \"count\":59\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Kenan\",\n",
    "      \"count\":58\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Hassan\",\n",
    "      \"count\":57\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Isma\",\n",
    "      \"count\":57\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Samanthalee\",\n",
    "      \"count\":54\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Alexa\",\n",
    "      \"count\":51\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Caine\",\n",
    "      \"count\":49\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Grady\",\n",
    "      \"count\":47\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Anne\",\n",
    "      \"count\":40\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Rihan\",\n",
    "      \"count\":38\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Alexei\",\n",
    "      \"count\":37\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Indie\",\n",
    "      \"count\":36\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Rhuairidh\",\n",
    "      \"count\":36\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Annoushka\",\n",
    "      \"count\":32\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Kenzi\",\n",
    "      \"count\":25\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Shahd\",\n",
    "      \"count\":24\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Irvine\",\n",
    "      \"count\":22\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Carys\",\n",
    "      \"count\":21\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Skye\",\n",
    "      \"count\":19\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Atiya\",\n",
    "      \"count\":18\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Rohan\",\n",
    "      \"count\":18\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Nuala\",\n",
    "      \"count\":14\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Maram\",\n",
    "      \"count\":12\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Carlo\",\n",
    "      \"count\":12\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Japleen\",\n",
    "      \"count\":9\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Breeanna\",\n",
    "      \"count\":7\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Zaaine\",\n",
    "      \"count\":3\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Inika\",\n",
    "      \"count\":2\n",
    "    }\n",
    "]'''\n",
    "\n",
    "info = json.loads(data)\n",
    "#print('User count:', len(info))\n",
    "\n",
    "sum = 0\n",
    "for item in info:\n",
    "    need = item['count']\n",
    "    sum +=need\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "data = '''\n",
    "[\n",
    "    {\n",
    "      \"name\":\"Haider\",\n",
    "      \"count\":100\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Mowmita\",\n",
    "      \"count\":99\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Roray\",\n",
    "      \"count\":94\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Ana\",\n",
    "      \"count\":92\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Zennon\",\n",
    "      \"count\":91\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Wen\",\n",
    "      \"count\":90\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Maddi\",\n",
    "      \"count\":88\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Naisha\",\n",
    "      \"count\":88\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Kallan\",\n",
    "      \"count\":86\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Theo\",\n",
    "      \"count\":84\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Diana\",\n",
    "      \"count\":84\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Tai\",\n",
    "      \"count\":79\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Rhanna\",\n",
    "      \"count\":78\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Jez\",\n",
    "      \"count\":77\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Nora\",\n",
    "      \"count\":76\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Zuhrah\",\n",
    "      \"count\":74\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Amrit\",\n",
    "      \"count\":69\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Brooklin\",\n",
    "      \"count\":67\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Nikela\",\n",
    "      \"count\":64\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Laibah\",\n",
    "      \"count\":62\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Jaymie\",\n",
    "      \"count\":56\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Caity\",\n",
    "      \"count\":55\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Justin\",\n",
    "      \"count\":53\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Louella\",\n",
    "      \"count\":50\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Sahra\",\n",
    "      \"count\":47\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Nazia\",\n",
    "      \"count\":46\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Abubakar\",\n",
    "      \"count\":46\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Kodey\",\n",
    "      \"count\":45\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Chiara\",\n",
    "      \"count\":40\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Eren\",\n",
    "      \"count\":40\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Raina\",\n",
    "      \"count\":40\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Tania\",\n",
    "      \"count\":38\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Limo\",\n",
    "      \"count\":35\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Dharam\",\n",
    "      \"count\":30\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Boys\",\n",
    "      \"count\":27\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Drue\",\n",
    "      \"count\":25\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Kym\",\n",
    "      \"count\":25\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Jayse\",\n",
    "      \"count\":24\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Carrick\",\n",
    "      \"count\":24\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Alara\",\n",
    "      \"count\":19\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Reegan\",\n",
    "      \"count\":17\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Erencem\",\n",
    "      \"count\":15\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Raya\",\n",
    "      \"count\":13\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Fyn\",\n",
    "      \"count\":11\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Della\",\n",
    "      \"count\":11\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Karson\",\n",
    "      \"count\":11\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Suzannah\",\n",
    "      \"count\":11\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Marnie\",\n",
    "      \"count\":8\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Buse\",\n",
    "      \"count\":4\n",
    "    },\n",
    "    {\n",
    "      \"name\":\"Enrico\",\n",
    "      \"count\":2\n",
    "    }\n",
    "]'''\n",
    "\n",
    "info = json.loads(data)\n",
    "#print('User count:', len(info))\n",
    "\n",
    "sum = 0\n",
    "for item in info:\n",
    "    need = item['count']\n",
    "    sum +=need\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_927507.json'\n",
    "r = urllib.request.urlopen(url)\n",
    "data = r.read()\n",
    "\n",
    "#js = [\"comments\"][0][\"count\"]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "serviceurl = 'http://python-data.dr-chuck.net/comments_42.json'\n",
    "\n",
    "while True:\n",
    "    #url = serviceurl + urllib.urlencode(('sensor': False, 'address' : address))\n",
    "    #print \"Retrieving\", url\n",
    "    uh = urllib.request.urlopen(serviceurl)\n",
    "    data = uh.read()\n",
    "    print(\"Retrieved\", len(data), \"characters\")\n",
    "\n",
    "    js = json.loads(str(data))\n",
    "    #js = None\n",
    "\n",
    "    print(js.dumps(js, indent = 4))\n",
    "\n",
    "    js = [\"comment\"][0][\"count\"]\n",
    "    lst = list()\n",
    "    lst.append(js)\n",
    "    print(sum(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location: http://py4e-data.dr-chuck.net/comments_927507.json\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "url = input(\"Enter location: \")\n",
    "address = urllib.request.urlopen(url)\n",
    "data = address.read()\n",
    "\n",
    "sum = 0\n",
    "while True:\n",
    "    if len(url)<1: break\n",
    "    print(\"Retrieved \", len(data),\" characters\")\n",
    "    \n",
    "    info = json.loads(data)\n",
    "    info = info[\"comments\"]\n",
    "    for item in info:\n",
    "        sum += int(item[\"count\"])\n",
    "\n",
    "print(\"Sum: \", sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location: Politecnico di Milano\n",
      "Retrieving http://py4e-data.dr-chuck.net/json?address=Politecnico+di+Milano&key=42\n",
      "Retrieved 2345 characters\n",
      "{\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"address_components\": [\n",
      "                {\n",
      "                    \"long_name\": \"32\",\n",
      "                    \"short_name\": \"32\",\n",
      "                    \"types\": [\n",
      "                        \"street_number\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Piazza Leonardo da Vinci\",\n",
      "                    \"short_name\": \"Piazza Leonardo da Vinci\",\n",
      "                    \"types\": [\n",
      "                        \"route\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Milano\",\n",
      "                    \"short_name\": \"Milano\",\n",
      "                    \"types\": [\n",
      "                        \"locality\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Milano\",\n",
      "                    \"short_name\": \"Milano\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_3\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Citt\\u00e0 Metropolitana di Milano\",\n",
      "                    \"short_name\": \"MI\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_2\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Lombardia\",\n",
      "                    \"short_name\": \"Lombardia\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_1\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Italy\",\n",
      "                    \"short_name\": \"IT\",\n",
      "                    \"types\": [\n",
      "                        \"country\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"20133\",\n",
      "                    \"short_name\": \"20133\",\n",
      "                    \"types\": [\n",
      "                        \"postal_code\"\n",
      "                    ]\n",
      "                }\n",
      "            ],\n",
      "            \"formatted_address\": \"Piazza Leonardo da Vinci, 32, 20133 Milano MI, Italy\",\n",
      "            \"geometry\": {\n",
      "                \"location\": {\n",
      "                    \"lat\": 45.4784315,\n",
      "                    \"lng\": 9.228342399999999\n",
      "                },\n",
      "                \"location_type\": \"ROOFTOP\",\n",
      "                \"viewport\": {\n",
      "                    \"northeast\": {\n",
      "                        \"lat\": 45.4797804802915,\n",
      "                        \"lng\": 9.2296913802915\n",
      "                    },\n",
      "                    \"southwest\": {\n",
      "                        \"lat\": 45.4770825197085,\n",
      "                        \"lng\": 9.226993419708496\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"place_id\": \"ChIJUxfRffbGhkcRdzNKd-H6MI4\",\n",
      "            \"plus_code\": {\n",
      "                \"compound_code\": \"F6HH+98 Milan, Metropolitan City of Milan, Italy\",\n",
      "                \"global_code\": \"8FQFF6HH+98\"\n",
      "            },\n",
      "            \"types\": [\n",
      "                \"establishment\",\n",
      "                \"point_of_interest\",\n",
      "                \"university\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"status\": \"OK\"\n",
      "}\n",
      "Place ID: ChIJUxfRffbGhkcRdzNKd-H6MI4\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    if not js or 'status' not in js or js['status'] != 'OK':\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        continue\n",
    "\n",
    "    print(json.dumps(js, indent=4))\n",
    "\n",
    "    place_id = js['results'][0]['place_id']\n",
    "    #lng = js['results'][0]['geometry']['location']['lng']\n",
    "    #print('lat', lat, 'lng', lng)\n",
    "    #location = js['results'][0]['formatted_address']\n",
    "    print('Place ID:',place_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
